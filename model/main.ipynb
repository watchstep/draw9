{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://pypi.org/project/quickdraw\n",
    "# from quickdraw import QuickDrawData\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "import glob as gb\n",
    "import pathlib\n",
    "import random\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split, TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(seed):\n",
    "    # os.environ['PYTHONASHSEED'] = 0 무작위화 비활성화\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "# 이미지 저장\n",
    "def save_figure(figure_name, figure_base_path = './figure/', figure_extension='.png', resolution=300):\n",
    "    # make directory\n",
    "    try:\n",
    "        if not os.path.exists(figure_base_path):\n",
    "            os.makedirs(figure_base_path)\n",
    "    except:\n",
    "      print('already exists')\n",
    "    \n",
    "    figure_path = figure_base_path + figure_name + figure_extension\n",
    "    print('save figure: ', figure_name)\n",
    "    \n",
    "    plt.savefig(figure_path, bbox_inches='tight', format=figure_extension[1:], dpi=resolution)\n",
    "    \n",
    "    \n",
    "set_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image labels\n",
    "def get_labels():\n",
    "  f = open('./30_labels.txt', 'r')\n",
    "  labels = f.readlines()\n",
    "  f.close()\n",
    "  \n",
    "  labels = [l.replace('\\n', '') for l in labels]\n",
    "  return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/banana.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bear.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bus.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/duck.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fish.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hamburger.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/house.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lion.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/nose.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/monkey.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pig.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rabbit.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shoe.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
      "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "  # make directory\n",
    "  dataset_path = './dataset/'\n",
    "  try:\n",
    "    if not os.path.exists(dataset_path):\n",
    "      os.makedirs(dataset_path)\n",
    "  except:\n",
    "      None\n",
    "      \n",
    "  # get data from web\n",
    "  labels = get_labels()\n",
    "  base_url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
    "  for label in labels:\n",
    "    label_url = label.replace('_', '%20')\n",
    "    npy_url = base_url + label_url + '.npy'\n",
    "    print(npy_url)\n",
    "    urllib.request.urlretrieve(npy_url, dataset_path + label + '.npy')\n",
    "\n",
    "  print('Done!')\n",
    "  \n",
    "load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/44429199/how-to-load-a-list-of-numpy-arrays-to-pytorch-dataset-loader\n",
    "# https://velog.io/@dust_potato/Data-Augmentation-%EC%96%B4%EB%96%A4-transform%EC%9D%84-%EC%A4%98%EC%95%BC-%EC%9E%98%ED%96%88%EB%8B%A4%EA%B3%A0-%EC%86%8C%EB%AC%B8%EC%9D%B4-%EB%82%A0%EA%B9%8C\n",
    "\n",
    "def prepare_dataset(test_ratio=0.2, max_items_per_class=10000):\n",
    "    npy_files = gb.glob('./dataset/*.npy')\n",
    "\n",
    "    #initialize variables \n",
    "    x = np.empty([0, 784]) # 28*28 =784\n",
    "    y = np.empty([0])\n",
    "    classes = []\n",
    "\n",
    "    #load a subset of the data to memory \n",
    "    for idx, npy_file in enumerate(npy_files):\n",
    "        data = np.load(npy_file)\n",
    "        data = data[0: max_items_per_class, :]\n",
    "        labels = np.full(data.shape[0], idx)\n",
    "\n",
    "        x = np.concatenate((x, data), axis=0)\n",
    "        y = np.append(y, labels)\n",
    "    \n",
    "        label, extension = os.path.splitext(os.path.basename(npy_file))\n",
    "        classes.append(label)\n",
    "\n",
    "    data = None\n",
    "    labels = None\n",
    "    \n",
    "    # transform to torch tensor\n",
    "    tensor_x = torch.Tensor(x)\n",
    "    tensor_x = tensor_x.reshape(tensor_x.shape[0], 1, 28, 28)\n",
    "    # normalizatoin\n",
    "    tensor_x /= 255.0\n",
    "    tensor_y = torch.Tensor(y)\n",
    "    \n",
    "    # create dataset\n",
    "    dataset = TensorDataset(tensor_x, tensor_y)\n",
    "\n",
    "    #separate into train data and test data\n",
    "    lengths = [int(len(dataset)*(1-test_ratio)), int(len(dataset)*test_ratio)]\n",
    "    \n",
    "    train_dataset, test_dataset = random_split(dataset=dataset, lengths=lengths)\n",
    "    \n",
    "    return train_dataset, test_dataset, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.12.1 DEVICE :  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda:0')\n",
    "else:\n",
    "  DEVICE = torch.deivce('cpu')\n",
    "\n",
    "print('Using Pytorch version : ',  torch.__version__, 'DEVICE : ', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, classes = prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train [N, C, H, W] : torch.Size([128, 1, 28, 28]) \n",
      "Type of X_train : torch.float32\n",
      "\n",
      "Shape of y_train [N, C, H, W] : torch.Size([128]) \n",
      "Type of y_train : torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "  print(f'Shape of X_train [N, C, H, W] : {X_train.shape}', f'\\nType of X_train : {X_train.dtype}\\n')  # X_train.type() : torch.FloatTensor\n",
    "  print(f'Shape of y_train [N, C, H, W] : {y_train.shape}', f'\\nType of y_train : {y_train.dtype}\\n')  # y_traon.type() : torch.LongTensor\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, label):\n",
    "  img = img / 2 + 0.5  # unnormalize\n",
    "  npimg = img.numpy()\n",
    "  plt.figure(figsize=(5, 5))\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.axis('off')\n",
    "  save_figure(label)\n",
    "  plt.show()\n",
    "\n",
    "def idx_to_class(y_idx):\n",
    "  return classes[int(y_idx.item())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save figure:  house\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEeCAYAAABcyXrWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAALMUlEQVR4nO3de6zXdR3H8e85BwG5K3jhooBGEzF0aSmwKeYNU3NZToukmbqplXPqH3ZxtlrLy3SWhrdqLjNL18yZm+jKSwFe0CneEEkQMOKqCBw5en7n19/+oZ+38fN9zu/H4/Evr31+P4/u6Wfzs2NbvV6vADK19/YXAHY+wgOkEx4gnfAA6YQHSCc8QLp+H/eHx7Wf7r+1A/+XR3rubfuoP3PjAdIJD5BOeIB0wgOkEx4gnfAA6YQHSCc8QDrhAdJ97MtlWk992sHFzcoTB4XO2v+ONaFd9xsrQjt2Hm48QDrhAdIJD5BOeIB0wgOkEx4gnfAA6YQHSOcBYYvY9J1pod19P7m2uBnXb0jorA1nbwvtpt91WXEz8fKFobNoDW48QDrhAdIJD5BOeIB0wgOkEx4gnfAA6YQHSCc8QDovl3tL20f+/+w/5I2rjgjtXvnWTaHdX7buU9ws69ordNaPRy0J7ZbOubm4mbjHuaGzDvzZutCue8XK0I7e4cYDpBMeIJ3wAOmEB0gnPEA64QHSCQ+QTniAdMIDpPNyuZesvOeg0O71GeVXv1VVVZ09tdDuzKFvFzddQ2Kvgyc+cGFoV/XvKU6Wzro1dFTXCR+EdjMWnR3ajfv+luKme9Xq0FnEufEA6YQHSCc8QDrhAdIJD5BOeIB0wgOkEx4gnfAA6bxc/hSsumJ6cfPqjLmhs7rqsZe6g9r7h3bratuKm2+fdE7orM8ufia0izh1yjdDuyXnjwjt5p96XWi36okBxc2ll3wvdNag+54K7XDjAXqB8ADphAdIJzxAOuEB0gkPkE54gHTCA6TzgPATaJ96QGj34LnXlDedo0JnnTQoNKtOXnpiaFe7aHhx07N4SexDg9qHDi1u3jp2ZOisWUc8F9qN7jckuCtvHrsp9utnT3ntzNCu9srS0K6VufEA6YQHSCc8QDrhAdIJD5BOeIB0wgOkEx4gnfAA6bxcrqqqrV/sx7D/b5eHdut7yr9Oc+5xJ4TO+vWWraFdbcOa0K6qyrv6jENCJy07ryO0e3DmjcXN5P7/DJ119cZJod3kWy8M7baPf7+4WT7rN6GzuvYuv9Cuqqrq90po1tLceIB0wgOkEx4gnfAA6YQHSCc8QDrhAdIJD5BOeIB0Xi5XVbXs6sNCu4fG3hLaHXblRcXNyOULQ2d1DBsW2q25ZHpo96XZTxc3N4y+I3TW6u7Yq+pjFpZfEY/5Xf/QWf3nLQrt9q0WhHbtB08uj2aFjqo2HVh+sV5VVbXnP2LntTI3HiCd8ADphAdIJzxAOuEB0gkPkE54gHTCA6Rr+QeE3V86tLh5/owbQmdNeuz80G6/28uPAzeeNy101tWX3xbaHbPrE6HdleunFDdTboz92tDxt78W2k3YsDi06w09Ly4tbqIPJTcfUAvt9gytWpsbD5BOeIB0wgOkEx4gnfAA6YQHSCc8QDrhAdIJD5CuaV8ud4wYHtrNnnt/cbNg+9DQWT1rB4Z2ey0s/7rSeeNvDp110X++ENr9/IKDQ7sBC8uvjbsvr4fOemPumNDuqAmdxc2cUfNDZ636YGRo9/vTjg/tai+Xfx5XrT0mdNbRh70c2q0OrVqbGw+QTniAdMIDpBMeIJ3wAOmEB0gnPEA64QHSCQ+QrmlfLq+9c6/Qbs6wxxv2mS+e/qvQ7vpNU4ub6O81Hnf1U6HdLj2LQrv3Tiq/hH7t7Nir6oc7dwntbltzVHEzZ/45obOemnlTaPfDC0eEdpO+W97M+/vnQ2e9dFbsn4/TJnytuOlesTJ0VrNy4wHSCQ+QTniAdMIDpBMeIJ3wAOmEB0gnPEA64QHSNe3L5ZljloV2t7wztrj54w9OCp015PHy7+etqqqqvbO5uBlXLQid1WiDX13fsLMuve280G7MNeW/1s9UG0JnXbwg9vfqK0c8G9q9Gtjsf++7obMGzIm95H7zzHHFzdirvFwGaCjhAdIJD5BOeIB0wgOkEx4gnfAA6YQHSNe0DwgnDNwY2s1demRxM/r+p0Nn1UKrvq37jRXFzfIPtobO2jqxewe/zSf35PzJod3ib/wytPv6qBOLm9qzL4fOeqhzQGjXNbUztGtlbjxAOuEB0gkPkE54gHTCA6QTHiCd8ADphAdIJzxAuqZ9ubxi+8jQbvdB733K36T1dLTFdm09wWEDjXss9lp60Oz+od2mWZOKm+F/iL2Sf3RL7FX12FHvhHatzI0HSCc8QDrhAdIJD5BOeIB0wgOkEx4gnfAA6YQHSNe0L5ff7Nw9tBszeHNxE3uXuvPYvT32j0VbV+NeLnd+9fDQbsjyLQ37zKqqqi37lv/dOzx41gtvjw3tDtptTXHzevAzm5UbD5BOeIB0wgOkEx4gnfAA6YQHSCc8QDrhAdI17QPCNduGhXZH711+irWx6tjRr9M82st/rUPaB4aO6mjgA8Ibrr8xtDv98Qsa9plVVVX9Oht31rL/7hHaXTHhgeLmp22Hxj60Xo/t+hg3HiCd8ADphAdIJzxAOuEB0gkPkE54gHTCA6QTHiBd075c3rRlcGg3cfz64uaZau8d/TpNo33woIad1ciXy+dee3FoN3p9LXbg8bFZzy6xXcTQf8V+tjNmlv99X582NXRW24IXQru+xo0HSCc8QDrhAdIJD5BOeIB0wgOkEx4gnfAA6YQHSNe0L5e71sZeiX758GXFzb0DxofOqnd1hXZ9WSNfLrc38Mex59wFsWFb7LX0muu2hnbbxgdfQgeMeXBVaFf7UU9xs/KE2Mv88cEfW1/jxgOkEx4gnfAA6YQHSCc8QDrhAdIJD5BOeIB0wgOka9qXy6MWxZo5+rQhxU339CmhszoefS6069N2Hdiwozreb9hRcfV6aHb3u7HfWTxq4qYd+TYf0v1m7OXyLzYeWNzsd+SK0FmNe3edy40HSCc8QDrhAdIJD5BOeIB0wgOkEx4gnfAA6Zr2AeEej73VsLPWTIs9qhv3aMM+stfUt3Y27Kzuxr1FbLibFx8Z2v11+s3FzWWDjw2d1bNtW2h335vlx42zJy4KnTWvGhba9TVuPEA64QHSCQ+QTniAdMIDpBMeIJ3wAOmEB0gnPEC6pn253L1iZWh3z9bhxU3HF9/e0a/TNGrr1xc3b9dir5u79ujZ0a/zqRlzd//QbsrMXYubzad8LnTW0D89Gdp9UOsobh5eNzl0VlU17gV/JjceIJ3wAOmEB0gnPEA64QHSCQ+QTniAdMIDpBMeIF3TvlyOumrJrOLmsgMeCZ11VzVuR79OU3iqa7fYcFTXp/tFdsDAvz0T2h125QXFzZ7zloTOqoVWVTX2rNXFTVtH7E4Q/cy+xo0HSCc8QDrhAdIJD5BOeIB0wgOkEx4gnfAA6Vr+AeF7i0YWN7MPXRc668/7HBHada8qPxDryy5adEZot8u/y782tNfU66HZyNsXFjeNfqTXs2VLg09sPm48QDrhAdIJD5BOeIB0wgOkEx4gnfAA6YQHSCc8QLqWf7k8+sn3i5uO82P93TBzn9BuxJ3N/XJ54pmLe/sr0OLceIB0wgOkEx4gnfAA6YQHSCc8QDrhAdIJD5BOeIB0Lf9yecATLxU362rbQmdtPCT2e3xH3BmawU7LjQdIJzxAOuEB0gkPkE54gHTCA6QTHiCd8ADphAdI1/Ivl3u2by9uTr7istBZk57fHPvM0Ap2Xm48QDrhAdIJD5BOeIB0wgOkEx4gnfAA6YQHSNfyDwgjdrtjYWjnYSA0hhsPkE54gHTCA6QTHiCd8ADphAdIJzxAOuEB0gkPkK6tXq/39ncAdjJuPEA64QHSCQ+QTniAdMIDpBMeIN3/AASY0AsjIQEOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "imshow(images[0], idx_to_class(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save figure:  quickdraw_visualization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAESCAYAAAD5QQ9BAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8jklEQVR4nO3debxN5f4H8M+XDKFCkVQoIsUtieZSSqOIiF8oXA234TbcJqWRNLsNt6JBAxWVFJGoKFRuNxKVisiQWQgprN8fa3t8n29nbfvss/c5+6zzeb9eXq/vOt+1917nrL32fqzn+zyPBEEAIiIiojgrVdQHQERERJRtbPAQERFR7LHBQ0RERLHHBg8RERHFHhs8REREFHts8BAREVHs5VSDR0Tmi8ipefz8BBGZk8XXnSgif8/W81P0uSWi+BCRFiKyqKiPg1InIrNFpEVELlbnc5eiPoBUBEHwCYAGRX0cREREcRIEwaFFfQyFJafu8BAREVHxJyI5d0MlFxs8zUTkGxFZIyKDRaS8va0mIvuLyAgRWSEiq0TkCREpKyKrRaSx2q+6iGwUkWqJ7TYiMkNE1onIXBE5I68DEJEeIvJt4hjGiUjt7P/aJcLhIjJTRNaKyDARKQ8AItJLRH5MnL93RKRm4ud1RCTQF47ufhSReiIyKfF8K0VkmNrvYBEZn3jOOSLSsbB/2ZJKRG4SkcUisj7xt28pIi+ISF+1j72m54vIv/J6f1BmJP7GNyT+xhtE5DkR2VtExibO1QQRqZLY99xEV8eviWuuoXmelM6ViFyd+DzfT0TKichDIvKziCwTkadFZNfEfrNEpLV6XJnENd0k23+XOIm49u4UkTcS52m9iHwpIoepx7hyAxHZNXGtrhGRbwA0M89fU0TeTHz3/iQiV6vc9tcZIiLrAFxcSL92ynKxwXMhgNMB1AVQH8BtOikipQGMBrAAQB0A+wJ4LQiCPwC8BqCL2r0zgA+CIFghIs0BvATgBgCVAZwIYL59cRFpA6A3gHYAqgH4BMCrmfrlSriOAM4AcACAvwG4WEROAdA/kdsH4Xl9LcXnuwfA+wCqANgPwOMAICIVAYwH8AqA6gA6AXhSRA7J2G9CeRKRBgCuBNAsCILdEF7L81N8+F/eH1k4xJKuPYDTEH62tgYwFuHnXTWE3wdXi0h9hJ951yR+PgbAKBEpq55np+dKRG5P/PykIAgWAbgv8bqHA6iH8LP79sTuL8H/7D4LwC9BEEwv2K9bcuzk2msD4HUAVRF+Lo4UkTJ5PM0dCL976yYef5F6/lIARgH4CuG5awngGhE5XT2+DYA3EH7HDs3Qr5YxudjgeSIIgoVBEKwG0A9ho0VrDqAmgBuCINgQBMHvQRBMTuReBNBZRCSx3RXAy4m4J4DngyAYHwTBtiAIFgdB8F0er38ZgP5BEHwbBMEWAPcivDPBuzwF91gQBEsS53YUwg++CxGely+DINgM4BYAx4hInRSe708AtQHUNO+DcwDMD4JgcBAEWxIfmm8C6JDh34f+aiuAcgAOEZEyQRDMD4JgboqPzev9QZn1eBAEy4IgWIzwP3OfB0EwPQiC3wG8BaAJgAsAvJv4rPwTwEMAdgVwrHqeZOdKROQRAK0AnJz4D6cAuATAtUEQrA6CYD3Cz9ZOiccMAXCWiOye2Naf3ZSaZNfe/4IgeCNxPh8BUB7A0Xk8R0cA/RLnaCGAx1SuGYBqQRDcHQTBH0EQzAPwDHacQwD4NAiCkYnv2E2Z/gULKhcbPAtVvABh40bbH8CCRGPEEwTB5wA2AmghIgcj/F/EO+pxqXzw1gbwaOJW7q8AVgMQhC1aKpilKt4IoBLC87tg+w+DIPgNwCqk9ve+EeG5mZa4/d4j8fPaAI7afg4T5/FCADUK/itQMkEQ/IjwzsCdAJaLyGuS6KJMQV7vD8qsZSrelMd2XtfkNoSfy/qaTHauKiNs3PQPgmBt4mfVAFQA8D91Tb6X+DmCIFgCYAqA9iJSGcCZyME7BLlsJ9feQrXfNgCL8NfvViR+Zr+Dt6sNoKb5XO0NYG+1j35szsm5oiKEDZPtagFYYvILAdQSkV3yavQgvMvTBeEF+Ubify7bH1c3hddfiLCFy4utcCxBeCEBcN1RewJYDGBD4scVAKxLxK7REgTBUgC9Eo87HsAEEfkY4TmcFATBaVk/evqLIAheAfBK4n/rAwHcj/D8VVC7sfGZu5YA0LWQgvBzeXGKj1+D8DN4uIicFwTBFAArETaoDk3cXcrLiwD+jvB76dMk+1GEiGtvLtT3aqJraj/89bsVAH5J7Ds7sV1L5RYC+CkIgoOSHUL6R599uXiH54pEgVtVALcCGGby0xCelPtEpKKERc3HqfwQAOchvOBeUj9/DkD3RBFXKRHZN3EXyHoawC0icigAiMgeIsKukOx5FeF5OVxEyiG8zf154nbsCoQfsl1EpHTiDo5rtIpIBxHZL7G5BuHFtg1hjVd9EemaKH4sIyLNdOElZYeINBCRUxLn8neEX3LbAMxA2GVRVURqIPyfKOWm4QDOTnxWlgFwPYDNAKam+gRBEExEeFd1hIg0T9xVeAbAABGpDgCJz2Bd/zESwBEA/gn/s5tSkOTaA4CmItJOwgEg1yA8n5/l8TTDEX7/VUl8tl6lctMArE8URu+a+ExuJCLN8nienJSLDZ5XEBaizkPYMu2rk0EQbEVYbFcPwM8Ib81doPILAXyJ8MvvE/XzaQC6AxgAYC2ASVB3FtR+byFsFb+WqDSfhfD2KmVBEAQTAPRBWGPzC8IGje4T7oWw0HwVgEPhf+g2A/C5iPyGsOvyn0EQzEvUB7RKPM8ShHf77kfYv03ZVQ5hcepKhH/36gjrsl5GWOw4H+H1bf8jQzkiCII5CP/D+DjC89gaQOvEwJD8PM94AD0QFjwfAeAmAD8C+Czx2ToBan61RM3HmwgLoUdk4FcpaaKuPQB4G+H35BqE9VHtEvU81l0Iu7F+QnidujqqxHfvOQjrtX5KvM6zAPbI/K+SHRIEOX0HKi0i8jyAJUEQ3LbTnYmIKCckRnbVD4Kgy053ppSIyJ0A6vFvmps1PAWSGN3TDuFoAyIiKgYSZQw9Ed6BIMq4XOzSSpuI3IOwC+rBIAh+KurjISKinRORXgiLYscGQfBxUR8PxVMsu7SIiIiItFjd4SEiIiLKy85qeHj7p+jJzndJGc9n0cvU+eS5LHq8NuOF12Z85HkueYeHiIiIYo8NHiIiIoq92A1LJ6Lct2DBAm972rRpLu7QgROb56q5c3csRzh69GgXV6hQwduvRo0dK4e0bNnSy9l9iQoL7/AQERFR7LHBQ0RERLHHBg8RERHF3s4mHkxpeN3Uqf4iumPHjnXxunXrvNx+++2XZwwA1apVS+Xlktpjjx3rmDVrlvoirvo4Z86c6eXmzZvn4t9//z3yOU455RRvu169eim/fhIc+hovxX7o69atWyO3y5YtG/m4zZs3u/joo4/2cmvXrnWxvt5yXOyvzbffftvbbtu2bb6fo06dOt72M8884+JTTz01ncPKlmJ/bZLDYelERERUMrHBQ0RERLGX9rD0AQMGuLh3795eLlm3T2GaM2eOt71x40YX33///V5u5MiRLk73+Bs1auRtf/3112k9D1Eu69Wrl7e9ePFiF48bNy7ycbfccouLZ8yY4eXGjBmTmYOjAtPnsEuXLl6udu3aLtbdXfvss4+337fffuviK664wst17bpjMfSFCxd6uV124UwplD28w0NERESxxwYPERERxR4bPERERBR7aXeYvv766y7ORs2O7cvda6+9XHzIIYd4uRNPPNHFemh4/fr1vf309g8//BD52nZ4/NNPP+1iO2Rd1zLpIfFEcfLbb7+5ePjw4V7ukksuiXzc5MmTXayvleuuu87b78wzzyzoIVKa5s+f72136tTJxfYzdPny5S7WUwtceuml3n4ffPCBi+30I7Nnz3bxV1995eWaNm2a4lET5R/v8BAREVHsscFDREREsZd2l5a+rf3dd9+l/Lh7773XxR999JGX00PFb7zxxnQPLdI999zj4ttuu83L/fjjjy5esWKFl2vfvn3kc+pb8Y8++mhBDzHn2Vm1r732Whdv2bLFy5UrV87FFStWTOv1dtttNxfXrFnTy+mux+rVq3u5/fff38UNGjTwcgcccICLOQw2NW+88YaLN2zY4OW6desW+bi+ffu6WJ8T/TlARUtfwwAgsmOS2rp163q51atXu7h8+fIu1ucW8EsGZs2aFfnapUuXzt/BEhUA7/AQERFR7LHBQ0RERLHHBg8RERHFXkZWS88PPVW5HroI+MMVq1atmumX9ujhlQCw9957u7h79+5ermPHji62QyztchJZkFMrMl9++eXe9tChQ11sVz5ev359Wq+hV99es2aNi5ctW+btt3LlShf/+eefKT+/XtH7wAMP9HJ6inxdowAAlSpVcrGdgkAP5W3ZsmWyly+WKzKfddZZLv7555+9nK7R0OcLAPbcc08X9+vXz8V6mYliLKeuzfz45ZdfXLzvvvt6uXPOOcfFo0aN8nL6fa9XuC9Vyv+/c/PmzV08bdo0L7dt2zYX22VKBg0atNNjz6JieW1SnrhaOhEREZVMbPAQERFR7BX6mNxatWq5WM/eCvizr9oZjX/99dd8v5ZeHR0ANm/e7OJkXSB2JtnBgwdH7qu7u4YNG5bfQyx27FQCp512movffPPNjLyGPtf6b//kk096+1188cUutjP36hW87bQJetvOuK27zWyXnM7p1aDt6+2kS6tY+vrrr12cbFZk232hu8xPOumkzB8YpWXJkiUutmUNeloO3dUP/LVbeTvdTQUA8+bNc7GdGX/OnDkutrM8E2UT7/AQERFR7LHBQ0RERLHHBg8RERHFXqHX8OgpyG0Nj146wNbf6GUKKlSokNZrV65c2cULFizwcv/9739dfP7553s5/XqTJk3ycu+//35ax1Kc6CGsuv8dAK688soCP78e3goAxxxzjIt1vY1dBqJ///4u1lPeA8ATTzzh4sMOO6zAx2hddNFF3rZdcqO4s9ffokWLXHzQQQdFPk7vZ9WrV6/gB2a8+OKLLj777LO93F577ZXx14uLP/74IzKn63E2bdqU0vPZ6Tr0+8BOAaLrHl9//XUv16NHDxf/73//83JHHnmki5977rmUjotI4x0eIiIiij02eIiIiCj2st6lZW+d2hk5tSZNmrj4zjvv9HJ6dtyi9Pzzz3vbepj25MmTvZwejpntmaOzyc6IrZ1yyikFfv7//Oc/3rbuxtJdhieeeKK331133eVi3b0F+EOn27RpU+BjtGy3zpAhQ1xs3/O58t7NDzvMWF+bJ598cuTj7EzLmu5STped+kBPTWBnBdYzBpNPzxC/2267eTndBWXLB9atW5fn8yXryrQzsOvuKDskfsKECS4uU6aMl+vZs2fka5QkCxcu9LbHjBnjYjt9i16NXpeFAMCzzz7rYj2Dtu0K1qUEtqzAvnc0PWt927Ztvdzhhx8e+bhs4h0eIiIiij02eIiIiCj22OAhIiKi2MtIDY8dVqxrMh5//HEvt3Tp0sjn0cMVbf+trhuwSz/YlaszTa8Orfs9rRNOOMHb1rUbl1xyiZfTNSd6Fe5cpIfi26nmGzZsWODn33333SNztWvXdrHtg+7bt6+L77//fi+nl0LIRg2PHYara1701PzAX1ejzhUffviht62nHLj88su93JdffpnSc9rlOPSK8+nWMv3+++8u/te//uXljjjiCBfrFd0pOV178c4773i51q1bu9hOHRLF1mdt3brVxXaZIL2chP0sL8l0fZStFdV/p08//TTjr61rc3TtDQBs2bLFxfpaBPwaLFv3p987ut4S8Gta7ZIz/fr1c3Emvl803uEhIiKi2GODh4iIiGIv7S4tfWvLDk2ePn26i213wrnnnutiPasmAPTq1cvF9rbaAw884OJWrVp5OT10ORPdWytXrvS29evZWUNFxMUXXHCBl9O/g575F/BvIQ4YMCD9gy0EuuujRYsWXk7//uk6/fTTve1q1aq5WM+6/NBDD3n71alTx8V2uKS99Zpp+pa9Zbtjc9XQoUO97YkTJ7rYdmmlynYr6S6u0aNHu7hu3brefgcffLCL7XtK3863q2u/8sorLk425UVJt3nzZm/76aefdrHuQgD8WbbPO+88L3fjjTe6WA9ZP/TQQ739dBnA0Ucf7eXuu+8+F+vpHEqa9957z9vW34d6dnvA/xs+/PDDXk6vDDBu3Dgvp0spBg4c6OV0KUHnzp1dbIe968/WZOUX9vrTz//nn396OT18/q233vJyettOLXHvvfe6uHHjxpHHEnmM+X4EERERUTHDBg8RERHFHhs8REREFHtp1/BcccUVLp4xY4aXGzt2rIttfYZ2zTXXeNt6qJodxqaHfOthk4DfTzls2LDog07RU0895W3PmzfPxVOmTPFy3bp1c7GdJv2RRx5xse3D1H3o119/vZezQ54Lm+3D1b+/7sPPFLtMwxdffOFi3T9ta760XXfd1dvu0qVLho4ub/Z8asWlhqdmzZretl4eYPHixV4u1aH1Rx11lLet3y/JatX0Sti2pkRf7+PHj/dyusaLfHo4sa2j0Z/Z9vNU10noJSjy44ADDnCxHXb81VdfpfWccaBXn9fLogB+zaf+DgX8608vvQP4Sxo9+eSTXk5PI2I/E6OmmrB1sFWqVHFxfmo29eegfQ/o6SVmzZrl5fTnvK7Ptdt66hEAqF+//k6PiXd4iIiIKPbY4CEiIqLYS7lLyw7H1jNB3nLLLV4uWTeWVqtWLW9bD2W09Iq7N998s5e7++67XbxgwQIX61l68+Pjjz/2tps2beriZs2aeTn9OyxbtizyOXUXIOAPU7errHfq1Cn1g80CvQK8ZYelZ4P+m+pZRb///ntvP/2e3HPPPb2cHuacDXHo0rrsssu87QcffNDFduir7p61pk6d6uIrr7zSy+kpKpLR3Zhnn322l/vmm29cbFfepmgvvPCCi23ZwRtvvOHi9u3bZ/U47Ozb2Z4ZP5fpleLt94X+TrVDyPXj/vjjj7Reu2LFipE5PaTcTjOjpwnJD33e7YzagwcPdrEtX9F/l1WrVnk5Pf2B/Z5mlxYRERER2OAhIiKiEiDlLq1p06ZF5tJdnHH//ff3tpN1aWn2Vry+Jfb666+72C40mKrZs2d7223bto3cVy+aZ7tctGTda0uWLEn52AqD7dKqUaOGixs0aFCox1K6dGkX24XkMr2wXH7EoUvLjrzq2rWriwcNGuTlevfu7WI9ag8AzjjjDBfbkV+6W+W4445zsR0JqReYtLeq9Wy8+hgBvwu7evXqXk7fire35fX7Kq70SB973Wa7G0v76aefvG1bFhBn9nNCzxZfr149L5fsnOiSCDv7tR7Va1coGDNmjIvtLOV6JJ0eJWm/lzNh9erV3va1117r4ltvvdXL6S41O7pQv5eSLTodhXd4iIiIKPbY4CEiIqLYY4OHiIiIYi/lGh49NNQ6/PDD03rxAw880NueMGFCSo/Ts0cC/mquGzZsSOtYNDtjsl2JW9OzUK5bty5yPzsTsKZXJ84FetVsADj55JOL5kByWNmyZSNzdmXqcuXKZftwMkLPiqxrbwBg1KhRLr7pppu8nK4F+uSTT7zcXnvtledr2WHv2m677eZt6zoIO72DnYk1Vbrep0mTJl7OrmJdXOm//Zw5c7xcu3btXKxXnAeA8uXLF/i1t23b5mJdZwUAF1xwQYGfv7h48803vW37t9D0TMj9+/f3cunOvq/Pc1HSqygAfo2grjMC/NmibQ2PrplNB+/wEBERUeyxwUNERESxl3KXVrLZHdO9Za9nSAaAq666KqXH2S4nvZ2fxc2i2GHFv/32W+S+egFUO0Ospm/x5iI93M8OX7TDBrNNL3qou1LsTKF6CLQd4pmJ2/LJ2JmdNTs7aDrDJ4uCXsTVLsynZ0JesWKFl3vnnXdcHNWFlR92KK/uPtTTTgB+V7s9Lr29dOnSyFyyc1mc6aH/dhZaPWXHW2+95eU6d+4c+Zz6faEXdLYzcevZ9n///Xcvp4dDx12dOnUic3ZW8scffzzLR5M7dJvBLqKqZ5zONN7hISIiothjg4eIiIhijw0eIiIiir2Ua3iywQ5Vs9tRZs2a5W3rmg9dh5CuY445xttOtnq4XpU72QrdL7/8cmTusMMOy8fRZYcdiq4V9rB0vVRI3759U3qMricA/ro8QaYlq1VZuXKlt10caxbse1kPWbfTSRx11FEZfW07rF/X8Nh6KDtslXbQK2Bfd911Xu7BBx90sZ1KQF9Ldnke/Rmtpwfp2bOnt59d5kOrW7dussOOlWQrw7do0aLwDiSH2Vpe+17KJN7hISIiothjg4eIiIhiL+UuLTu7sWZXw832LfxkMzK3bNmywM9/1llnedvDhw93sR6eC/irzFqLFy928c033+zldDdR69at0zrOTNLddna13MK+BT116lQX6y6Lf//7395+w4YNc/GAAQO8nH5PZuP9mJ8ureJo/fr13va4ceNcfMMNN3i5TEwFYbuptUqVKhX4+Us6e45q167tYjvTsp4dePny5V5OT/egSwks/bhTTz3Vyx133HEpHHE82NXLO3bs6OJjjz22sA8nJ9lVCJKVhhQU7/AQERFR7LHBQ0RERLHHBg8RERHFXso1PGeccUZk7t133/W27ZTZmWanl9ertScbDpkqu8KsXlpBLyUBAB9++KGLf/31Vy+nl5qwQ22ffvrpAh5lZn322WcuPv7444vwSIAffvjBxfp9Z4c/6zoEW98zYsQIF19//fUZPsLkNTx2aYniSA9pBvylZVKdPiIZez3olaLtytBdu3Yt8OuR79lnn3Vx7969vdzo0aMjH6fr0/7xj3+4+IMPPvD2a9WqlYvt0hV6qYkKFSqkeMTFk13dW9cdUuHjHR4iIiKKPTZ4iIiIKPZS7tKyQ5X1cOyHHnrIy11wwQUurlatWuRzbt261dvWQ1PtMHg9HPzTTz/1cpleXXW33XbztvWQZz2sEPBvv9vfZ/Xq1Xk+B/DX1YsLm12RWg/j7tatW6Eey8aNG73thQsXujjZzNn6dniTJk283JAhQ1ysb68DfvdMfgRB4OIlS5ZE7pdLw9JtN+umTZtc/Pnnn3s5PeOuvcbKlCnj4kcffdTLtWnTxsWpTmHQp08fb3vmzJkuttNOVKlSJaXnpNQ1btzYxffee6+XS9alpZ122mkufumll7ycnq158ODBXk53N+uuTKJs4x0eIiIiij02eIiIiCj22OAhIiKi2BNdl5CHyKSut7Gri+vntLU/uj9+9uzZXm7dunUu7ty5s5fTffx2mvQZM2a4uHTp0lGHnBGXX365t62Hl9tVz3U/uV6dGABq1KiR6ksWfN7+HdyJGT9+vJfQdS52am87TDgT9LBn+x7Ux6Zrc9asWePtN3/+/IwfV7rKlSvn4rFjx3o5s9p8ps5n0gt3OztNw4oVKyL31Us4NG/e3Ms1atTIxc8995yX27BhQ577AcCZZ57pYr1cxcCBA739rr32Whc//PDDkceYY7JybRa1ZEuF6DovXV9nP88eeeQRF993331erlOnTi629WBFrFCvTcqqPM8l7/AQERFR7LHBQ0RERLGXdpeWNnnyZG9bD2u0w3f1KroNGzb0cnqGXz00GfBveY8aNcrLnXPOOakcZkZ8++233rbulmvfvr2Xy8Qq0sjSbfP//ve/XuL22293cbJVkNNlh4L/9ttvka+nu6r08H3dRQj43Se261RPEWC7OfW0A7vskvLMDB47g2qdOnVcnGwWZhTybfP333/f2/7xxx9drFeiB4C//e1vLk72d1m0aJG3ra9HO+u6noFXTyNgr9lBgwa5WHcP5rhYdGnZKSrKli0bue9FF13k4hdeeMHFerZ7AKhZs6aL7TQNOjdy5Mh8HGnWsUsrPtilRURERCUTGzxEREQUe2zwEBERUexlpIYnXXaI7NKlS118+umne7kGDRq4+KOPPsrmYeWaWNQJkFOi6gSeeOIJF7ds2dLFtn5v7dq1LtbD3AG/5iPHxOLatEu7VKxY0cXly5ePfNyyZctc3LdvXy8Xdd4Bvz5TTymSA0rUtRlzrOEhIiKikokNHiIiIoq9Iu3Satu2rbf99ttvu7hq1apebtKkSS62s7nGXCxum5NTom6b65nVL730Uhfb2Xf1lA56NW3An8X3yCOP9HJNmzZ1cevWrSNzWRLLa1PPoKynMQCAvffeO8+cna5Dz9RdpkwZL6dXUtfTFuSAEnVtxhy7tIiIiKhkYoOHiIiIYo8NHiIiIoq99ObVz5A77rjD265bt66Lu3fv7uVKWN0OUSzoJT8WL14cuZ9eNbtVq1Ze7ssvv3TxF1984eX00hm2HkSv7E2pO+2001w8d+5cL/ef//zHxZUqVXJxs2bNvP3atWvnYluT1aVLl4wcJ1F+8Q4PERERxR4bPERERBR7RTosnVISy6GvJViJGvo6ceJEF+tV6jM1ZPyPP/5w8ZYtW7ycXp09S2J5bW7atMnFa9as8XKpznqtZ82fMGGCl8vhLq0SdW3GHIelExERUcnEBg8RERHFHhs8REREFHus4cl9sawTKMFYJxAfvDbjhddmfLCGh4iIiEomNniIiIgo9nbWpUVERERU7PEODxEREcUeGzxEREQUe2zwEBERUeyxwUNERESxxwYPERERxR4bPERERBR7bPAQERFR7LHBQ0RERLHHBg8RERHFHhs8REREFHts8BAREVHsscFDREREsccGDxEREcUeGzxEREQUe2zwEBERUeyxwUNERESxxwYPERERxR4bPERERBR7bPAQERFR7LHBQ0RERLHHBg8RERHFHhs8REREFHts8BAREVHsscFDREREsccGDxEREcUeGzxEREQUe2zwEBERUeyxwUNERESxxwYPERERxR4bPERERBR7bPAQERFR7LHBQ0RERLHHBg8RERHFHhs8REREFHts8BAREVHslcgGj4jUEZFARHYp6mOJMxGZLyKn5vHzE0RkThZfd6KI/D1bz0/5IyIviEjfoj4OIirZ+IVPhS4Igk8ANCjq4yAiopKjRN7hISIiopIl5xs8InKziMwVkfUi8o2InJf4+cUiMkVEnhCRtSLynYi0VI+bKCL9RWSaiKwTkbdFpGrEa+whIs+JyC8islhE+opI6cL6HWOuWeK8rRGRwSJSXkRaiMii7TuIyP4iMkJEVojIqsQ5LSsiq0WksdqvuohsFJFqie02IjIjcX7nisgZeR2AiPQQkW8TxzBORGpn/9cuuUSkiYh8mbhmhwEor3K9ROTHxLl9R0RqqlwrEZmTuJ6fFJFJ7JosWhHX5p0iMkTt45UI5OezlwpXST+fOd/gATAXwAkA9gBwF4AhIrJPIndUIr8XgDsAjDAnohuAHgD2AbAFwGMRr/FCIl8PQBMArQDwgzYzLgRwOoC6AOoDuE0nEw3L0QAWAKgDYF8ArwVB8AeA1wB0Ubt3BvBBEAQrRKQ5gJcA3ACgMoATAcy3Ly4ibQD0BtAOQDUAnwB4NVO/HPlEpCyAkQBeBlAVwOsA2idypwDoD6AjwmtyAcJzDBHZC8AbAG4BsCeAOQCOLdyjJy3q2kzx4al+9lIh4fkEEARBsfoHYAaANgAuBrAEgKjcNABdE/FEAPep3CEA/gBQGuHJDhDWMO0NYDOAXdW+nQF8VNS/a3H/h7ABcpnaPgthA7UFgEWJnx0DYAWAXfJ4/FEAft5+jgF8AaBjIh4IYEDE604E8PdEPBZAT5UrBWAjgNpF/feJ4z+EDU97XU4F0BfAcwAeUD+vBODPxPXYDcCnKicAFm4/j/xXJOcyz2sTwJ0Ahqht93ma2I787C3q36kk/+P5DHL/Do+IdEt0W/wqIr8CaITwjg4ALA4SZyBhAYCaanuhyZVRj92uduLnv6jXGAigeuZ+ixLNnoOaJr8/gAVBEGyxDwyC4HOEjZMWInIwwjtw76jHzU3h9WsDeFSd29UIv0z3zc8vQSmribyvy+257TGCIPgNwCqE56Im1Hsl8fhFoKIUeW2mIJXPXipcJf585vQorUStxTMAWiL8399WEZmB8AsLAPYVEVEfrrWw4wsRCE8wVO5PACvNzxcivMOzV5pvBErOnoMlJr8QQC0R2SXi7/8iwm6tpQDeCILgd/W4uim8/kIA/YIgGJq/w6Y0/YK8r8u5CM+9q58SkYoIu68WJx63n8qJ3qYiEXVtbgBQQW3XyOOxUZ+9VHRK/PnM9Ts8FRHeWlsBACLSHeEdnu2qA7haRMqISAcADQGMUfkuInKIiFQAcDfCL8yt+gWCIPgFwPsAHhaR3UWklIjUFZGTsvdrlShXiMh+idqqWwEMM/lpCL/s7hORiomi5uNUfgiA8xA2el5SP38OQHcRaZk4Z/sm7gJZTwO4RUQOBVyBeocM/W70V58i7OPffl22A9A8kXsV4Tk7XETKAbgXwOdBEMwH8C6AxiLSNlEseQXy/uClwhN1bc4AcKKI1BKRPRDWXVk7/eylQlfiz2dON3iCIPgGwMMIP0SXAWgMYIra5XMAByFsafYDcH4QBKtU/mWEBclLEY4UuTripboBKAvgGwBrEBZP7hOxL+XPKwgblPMQ/i/fm4AucdG0Rthd9TPCbowLVH4hgC8RNnw/UT+fBqA7gAEA1gKYBHX3QO33FoD7AbwmIusAzAJwZsZ+O/IEYbF5O4Q1dqsRnssRidwEAH0AvInwg7cugE6J3EoAHQA8gLCb6xCENVubC/UXICfq2gyCYDzC/7jMBPA/hIWwVqqfvVRIeD53FIMWOyJyMcKCxuMj8hMRFmI9W5jHRZknIs8DWBIEwW073ZliQURKIfxAvjAIgo+K+ngodfzsjZc4nc+cruEhEpE6CO8YNCniQ6EsE5HTEd613YRwugEB8FmRHhQRxUZOd2lRySYi9yDsgnowCIKfivp4KOuOQdjtuRLhrfe2QRBsKtpDIqK4KLZdWkRERESp4h0eIiIiij02eIiIiCj2dla0zP6uoic73yVlPJ9FL1Pnk+ey6PHajBdem/GR57nkHR4iIiKKPQ5LJyIiZ8WKFS6uVq2al/vjjz9cvHLlyjxj+xzLly/3cmvXrnXxLrv4X0F77LFHnjEA7LbbbpG5gw/eMcl6qVL8fzzlje8MIiIiij02eIiIiCj22OAhIiKi2GMND5U4W7fuWOS3Qwd/4fRbb73VxU2bNi20YyLKJl03AwC9evVy8fz5873cF1984WJdNwMA69aty/zBZcBzzz3n4h49ehThkVAu4x0eIiIiij02eIiIiCj2SlSX1ubNm11crly5IjwSKkq//PKLi9966y0v17ZtWxezS4vi4s8///S2169f72IRf442vb7ieeed5+UaN27s4r322svFe+65p7efHs5evXp1L1e5cmUXb9myJfK41qxZE5k75ZRTvNyyZctAtDO8w0NERESxxwYPERERxR4bPERERBR7savhmTt3rovvuOMOLzds2DAXz5w508s1bNgwuwdGOWPVqlWROV2XQKnZsGGDi++55x4vp+sw6tat6+Krr77a2698+fJZOjoC/vq+Hjt2rIsnTJjg5U477TQX/+Mf//ByzZs3z8LR7WCXsohSoUIFb3vjxo3ZOJxYsTVRI0aMcLH+brRLgeyzzz4utkuB6M9S+/x6u2zZsl6uXr16ecYA0KxZMxd3797dy9nXzy/e4SEiIqLYY4OHiIiIYi8WXVrDhw938UUXXeRiexutT58+Lj7ooIMin0+vCJzX81DxZld21uzwWvqrxYsXe9stW7Z0se5SBoCaNWu6eOHChS7+7LPPvP3eeOMNF9vuiWeffdbFn376qZerUqWKi9u3b+/ldNcMRStdunRkbtu2bYV4JKmzXVq6W7UkGzVqlLf9zDPPuHjcuHFeTn/P/e1vf3Ox7WLSK9/baQSqVq0a+TjdTW0fp2f3fu+99yKPWccA8Pzzz7u4UaNGyC/e4SEiIqLYY4OHiIiIYo8NHiIiIoq9YlnDY/trL730UhcfddRRLh46dKi334cffujiE044wcvNnj3bxXoKcwB48cUXXdytW7c0jphySbIaHg5Lz9umTZtcfM4553g5Pa3/5MmTvZy+Hu+66y4X33nnnd5+ut7mk08+8XJ6WQQ7fF2v5j1w4EAvp2v7OnToAMpbshoeW3uRK2wNj35/lmRdunTxtnX96Y033ujlOnbs6OKbbrrJxbY2Zvr06S7u2bOnlzv77LNdbN9HRxxxhIuXLl3q5XS9zzXXXOPl9NDz/v37ezk9ZP2rr77ycvXr18fO8A4PERERxR4bPERERBR7OdulZbuV1q5d62K92jUA/Prrry7Ws0Iefvjh3n7JujK0Fi1aeNv77befi213WsWKFVN6zpJOd20AwLRp0/L9HPZ27csvv5zWsdhboZoe5kw7DB482MUzZszwcuPHj3exvR709Whva2u6u9mu3n3mmWe6WM8QDPjnslevXl7uiiuucPHJJ5/s5UpC16UeUv7bb795ud13393FpUpF/7+Xw9KLF93FBAAfffSRi203sj7vNWrUcHHfvn29/fR7wM7Kvccee7i4Tp06Xu7xxx938UMPPeTl9HV7/fXXI0rlypW97d9//z3yWNilRURERAQ2eIiIiKgEYIOHiIiIYq/Qa3h0f/+VV17p5X744QcXB0GQ1vO/9tpr6R2YMnHixMhtW1/QuHFjF1911VVeTi9zUaZMmQIfV3GWbDXj2rVre9uXX355nvsdc8wx3rau85o3b56X+/zzz108depUL/fOO+9EHoteNTjqOEoCW7vx6KOPuvikk07ycvq9rYeNAn6fe7r0ebDT0L/77rsu1ktQAMAhhxwSmbv55psLfFy55uGHH/a277vvPhcnq1/UQ/utrVu3FvzAssDWisW9hmfOnDkutrWp+lqtVKmSl1u9erWLbR3bvvvu6+ImTZq4+IsvvvD20++BJ5980svpZSemTJni5fS1P3LkyMjHvfTSS15OL0+j2wuAX6+rh72nind4iIiIKPbY4CEiIqLYk510HaXVr6RvZfXu3dvLDRgwwMX21pxe7dgOR9O36l555RUvZ297bWdXOdczS15wwQVezs7gqulVZWfNmuXlRo8e7WI7Q6wepqeH6AF/na02Cdn5LilLr58wCb169TfffOPl9OyntltJdxPq25SAv5K9/tsvWrTI288OtY2y//77e9t6SK6eYRvwb/vqodIZlKnzmfFzqdluvzZt2rj4hhtu8HK6KyUbw5ivu+46F48YMcLL6fOlV1IGgKZNm7p477339nJjxozJxKEV+bW5fPlyF9eqVcvL6dnk9fkDgHXr1rn4u+++83J6ugf72Xrqqaemc5gZZ7tVdRdXAc5tkV6b+tp55JFHvFyfPn1cbMsj9DmxXch6GgfbBaRn0f76669dbLsL27Zt62I9fB3wZ0W239n6+3fVqlVeTn/uzpw508v99NNPLrbtE33e9ZB74C/lJnmeS97hISIiothjg4eIiIhijw0eIiIiir2MDEu3Sz3oqeBt/5zu/7dTWNuamyh169b1tnU/c7t27Vysh2UCfm1Ius466yxvW69Aa/sU9Qq0tg/9qaeecvEll1xS4OMqKnoF7HHjxkXuZ2soDj74YBc3aNDAy+npyvV769xzz/X208MqbZ2OHh6tlwYB/KnMbQ2PfS+XVIMGDfK2dT3av//9by935JFHutguGaLPy8KFC12s+/4Bv57A1qL8+OOPLm7YsKGX+/bbb/M6fAD+ciZ2WGxcDBkyxMW63g3wz6FdyVpP25BstfRcXVoiDsPS7ZD/iy++2MX6vAJA586dXfzYY495Ob1Mil16RW/bqRn0UPTvv//exXZ6A13LaGtx9O+g68KscuXKedv6Oj7uuOO8XIcOHVx8//33e7nzzz/fxXaKmFTwDg8RERHFHhs8REREFHtpd2npW4h2iPX8+fNd/MEHH3g5O9tjOvRwU8C/3a6HumeiCys/7O+mh6nbYfD//Oc/XWy7u2z3Ty55/fXXvW3djXXttdd6udtvv93FdshiUUq2UrbuWilp9DB/e93qbmp9fQN+10nr1q29nO7GatGihYvtcFPdFWZvm+vV2fXUFYC/irtVvXr1yOeMC73qdL169bzc4sWLXWyHk2/evDml57ddj7li11139bb1zL25THcB6S4swO/G0jObA8DVV1+d0vMnKwtJds71SuMDBw5M6bV2Rg+Rt++jZO+rUaNGReaOPvroAh0T7/AQERFR7LHBQ0RERLHHBg8RERHFXtodtHrV1OnTp3s5PUw8EzU7VoUKFbxtvaSBHf5WlPSx6CU1AODAAw908fDhw72cXXU9l+jh9ABw2GGHufjBBx/0csmGuxalZDU8JZleidxOUa+XXrGra+shzrpmB/CH07766quRr33AAQe42A4x/vnnn128fv16L6eXJVm6dKmXq1KliovtkG39GnaIc3GyYMECF9v3tR6yb+s3jj/+eBfbFbb1+6C4XCu5uqq71aNHDxfboee6bifVmh1rn332icwtWbIkredMV7LlmpLRdWm21kd/36SDd3iIiIgo9tjgISIiothLu0tLr6irh5sCQMuWLdM+oHTYIYq5KNmwbLv6ba7R3QF6dXTAH4qeq11YtqvNdi9qtiunJNHDQe2qyHoFYz2zMuDPmG67sPXMqLpLyw4vnTdvnovt7Nd6KPoLL7wQefx21uWqVatG7rt69WoXF+cuLT2b9AMPPODlDj30UBdffvnlXk7/HTdt2hT5/La7K1fYGaBzdfi8nqUYAF566SUX9+/f38ul242l2VnlNT1NQS7TXW/VqlXzcgX9ruQdHiIiIoo9NniIiIgo9lK+D6hnOwWAr7/+2sXJZjulULKZXpPdes8FeiSM7fKxC7nmCt0Foxd4BYBGjRq52C4WWpJmWrYjW8aMGePi8847z8vpLmzbbaVHZg0bNszL2VmZt/vuu++8bd3FZUcG6QUQ9ehGAFi2bFnkc9oFZTXdpZVsv1ynF0i2iynqUT/2urVdlpru4qpZs2ZBDzEr7Hs3V7vT9Ygjy3YzZsLuu+/ubesRlcWlS0uPtkw26iwdvMNDREREsccGDxEREcUeGzxEREQUeynX8EyYMCEyZ1cwpr96//33I3ONGzcuxCPJPztLrZZsdd6i9M4770Tm9t13XxfPmjXLy+maEDvdgh5GeswxxxTwCIve5MmTve2VK1e6uEGDBl5O14DYejQ9+6n9u+i/dalSO/5/ZVdL10PbLT2z+g033ODl/vWvf7l4ypQpXu6KK66IfE5dw1Oc6bodXc8D+LVrtrZK1zt9/PHHkbl0Z8vNNltrl6s1PHraAOuuu+7yth955JGMv76+/hYtWpTx588GXVfJGh4iIiKifGKDh4iIiGIv5S6tZDPQ2sUE6a+eeeYZb/u4445zccOGDQv7cPIlWZdWrswS/eeff3rbekZTa9y4cZE53dUyadIkL3fssce6+KabbvJy/fr1c3Gu3l4H/L+THa6/9957u3jmzJleTl/jejFPAGjdunXk69WqVcvFbdq0cbGeWRkAmjZtmuywnYsuusjb1l1atouuT58+kc8Tly6tZPR0F8mGQF922WXednH429iZlnP1mtOfGYDfJWtngNcL6GZqAWk9rUBxHJZ+yCGHZPS5eYeHiIiIYo8NHiIiIoo9NniIiIgo9nJzidmY0MM97dIcyWpMioLut9fLMgDA5s2bIx+3YsWKrB3Tzuh6m549e3q5L7/8MvJx5cqVc/GIESO8nB7GaWvTnnjiCRfff//9Xk4vh6DrSgqDHVqva2pee+01L/f222+7eNq0aV5Or6B9ySWXeDld5/HYY495uSOOOCKl49R/o+nTp6f0GGvPPfeMzC1YsMDb1rUAVrI6lSFDhrj4xBNP9HK6Jiku7DQDub7UDVB8lpawdK2ffb/q1dLvvfdeL6ene7BTP+hlWWwtnF49/dNPP03jiAufnhpE1xVmAu/wEBERUeyxwUNERESxxy6tDLJD93U3QJ06dbxchw4dCuOQItmh5nqYvF11+oQTTnDxxRdf7OXsjLyFSd8S1qt5A373iZ5BGPC7LM4666yUX0/PhGq7/R544AEX2yHAFStWTPk10rFmzZrIbTtbtH6PnnvuuV5u6NChLrZdBPq82y4tPRNyMrvuuquL7RBZ3fXWqVOnyOdINj2GXSn6mmuuidxXz+b6zTffeLmuXbu6eNCgQV6uV69ekc9ZXNnro1q1akV0JKkrrl1aehoPO/u1/k6wU2d89tlnLh45cqSX0137u+zif6XrLiH9ngf8a1B35Rc227W3adMmF9etWzejr8U7PERERBR7bPAQERFR7LHBQ0RERLGXcg2P7RvUNmzY4G1nu2YhV9mVnHUtzMSJE71cUa9CbIdt62PV9SgAcM4557h47dq1Xk4vVWCnSq9UqZKLu3Xr5uUy8R7RdVF2CPJDDz3kYluH0b59+wK/9q233uptN2vWzMV66DcA/N///V+BXy8Zu6yG7rf//vvvIx9nV5TX50sPwQeARo0aubhKlSpe7qOPPnKxPc/6vOiaBXvMnTt3drGu9QH8JSkWLlyIKD169PC27ZB87Y477sgzBvzPurPPPjvyOeLC1oAdfPDBRXQkqbM1PGXLli2iI8mc888/P8/YWrdunbetp5ewQ8/1986SJUu8XN++fV381FNP5etYM2nKlCmROTsEv6B4h4eIiIhijw0eIiIiir2Uu7RatWrlbffu3dvFdrXk4cOHu1gPD44j/Xew3QC33367i+2MrUXNDkXVTj/9dG97zJgxLk42i7CIeNt6uOSdd97p5fTswJkYBmtn5NTHYofgz54928W6qyY/kq3iW9izT59yyine9pw5cyL31bOYzp8/38vp1ZqrV68e+Rx2FmbdBWqnW9CrouvXtrex9crtduoDPUu5ng0a8M+zXcFeTyMwcOBAL6dnsrVdaPp30KtNx9Xy5cu97eOPP76IjiR1ixYt8rb11BlxZ6dfOPXUU/OMAaBPnz4utp/Bd911l4v1tCRdunTJxGGmbPLkyd62num7YcOGGX0t3uEhIiKi2GODh4iIiGKPDR4iIiKKvZRreOyKyHqIqR0OeuSRR7r4zTff9HJ2Ndd02GF5enitrl9o3ry5t5+uo9ljjz1Sfj09tNbWCehVz6+77jovp/tIc40diqrZ1ZKvuuoqFx922GFeTtdQ6KHZgD8F+kUXXeTlfv75ZxdnYyr7Cy+80MV2Cnd9nH//+9+93KWXXupiW6dTqtSO/x/Y5Qii9ss1utYp3ZWI7777bm970qRJLtZ/d8CfOkDXSx177LHefq+++qqL7Xusbdu2LrYrw3fv3t3FNWrUiDxmvcxLXtslmf0s0DVv27Zt83JF+d7esmWLi+30BAceeGBhH06xo2tKAX+5Cn092Lo1Xd9Trly5jByLnspm7NixXk7XkNm60ILK3U9mIiIiogxhg4eIiIhiL+3V0vXQTTt07LzzznOx7VbSQ57tUG09+669lTVhwgQX25Vk9QrKejVaO5urvh17+OGHeznbjaN9/vnnkc/Zr18/F+sh6rlu9erVkTk7a6netsMek6ldu3ZkTq+Imw26W2T69Ole7rbbbnPx4MGDvZydWkCrXLmyi3/99VcvV6tWLRfb7ru4se+PESNGuNgOS9fDz/Xfz3ZBJJt5Ww9Lt11mduV2So2eMkJPRwAAzzzzjIvHjx/v5XSXr+5OTLd7ND90N7j9HK5Xr17WX7+4s92RQ4cOdbEuQ2nZsqW3n5553F63hx56qIvtyuZ6BftVq1Z5udGjR0fmXn755bx/gQzgHR4iIiKKPTZ4iIiIKPbY4CEiIqLYE92Xm4ekySh6Re3HH3/cy7344osu/vHHH1N+Tt3P3LFjRy+n6wZ07cYXX3zh7ffhhx+62K4qq+uALD20Vtd/AMnrVDIkk+Py3Pl87733vMS5557r4v3228/LPf/88y7WQxQBv2bKmjp1auTj9Lk4+eSTkx50NtkhubpvecGCBV5O1z3pmh0AaNeuXWTOyNT5TOvaLGz676mXKLGrXeuaqAoVKni5K6+80sWZmNYig7JybRY2O/RcX5uDBg3ycnqaEV3boVe0B/zlR2xNSLpDjd9//30X2+Vv9BDro446Kq3nRwm7NjVdR/PJJ594uW+//dbFX3/9dWTOfl7qtoVdvkXXgvbs2dPLnXTSSakedjJ5nkve4SEiIqLYY4OHiIiIYi8rXVrpskN9NT2ktYQplNvmuvuva9euXu67777bcTDmdrSelVN3/QH+6thz5871cosXL3bxPvvsk+yY46bE3jaPoVh0aeXHTz/95GI9fN1O76Bnp69fv76X091dnTp18nK6O9N2e15//fUuHjJkiJdbsWKFi5NNMbITvDbjg11aREREVDKxwUNERESxxwYPERERxV5O1fBQngq9TmDjxo3eth5aPG/ePC+nhyLaYYl6yHq3bt28XPv27VM5lDhinUB8lLganih2qYeRI0e6+Omnn/Zyeth7uu655x5v204XkiZem/HBGh4iIiIqmdjgISIiothjl1bu423zeOFt8/jgtZmGH374wcXvvvuul9u8ebOL7RQYegbeAsymnAyvzfhglxYRERGVTGzwEBERUeyxwUNERESxxxqe3Mc6gXhhnUB88NqMF16b8cEaHiIiIiqZ2OAhIiKi2NtZlxYRERFRscc7PERERBR7bPAQERFR7LHBQ0RERLHHBg8RERHFHhs8REREFHts8BAREVHs/T/GvPWNiUgc4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "for i in range(10):\n",
    "  plt.subplot(2, 5, i+1)\n",
    "  plt.axis('off')\n",
    "  plt.imshow(X_train[i, :, :, :].squeeze(), cmap='binary')  # X_train [32, 1, 28, 28] -> [i, :, :, :] -> squeeze() -> [28, 28]\n",
    "  plt.title(idx_to_class(y_train[i]))\n",
    "  \n",
    "save_figure('quickdraw_visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing PyTorch module\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "num_classes = len(classes)\n",
    "resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "resnet50.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(resnet50.parameters(), lr=1e-4)\n",
    "sheduler = optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=10, gamma=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           3,200\n",
      "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
      "              ReLU-3           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
      "            Conv2d-5             [-1, 64, 7, 7]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 7, 7]             128\n",
      "              ReLU-7             [-1, 64, 7, 7]               0\n",
      "            Conv2d-8             [-1, 64, 7, 7]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
      "             ReLU-10             [-1, 64, 7, 7]               0\n",
      "           Conv2d-11            [-1, 256, 7, 7]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 7, 7]             512\n",
      "           Conv2d-13            [-1, 256, 7, 7]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 7, 7]             512\n",
      "             ReLU-15            [-1, 256, 7, 7]               0\n",
      "       Bottleneck-16            [-1, 256, 7, 7]               0\n",
      "           Conv2d-17             [-1, 64, 7, 7]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 7, 7]             128\n",
      "             ReLU-19             [-1, 64, 7, 7]               0\n",
      "           Conv2d-20             [-1, 64, 7, 7]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 7, 7]             128\n",
      "             ReLU-22             [-1, 64, 7, 7]               0\n",
      "           Conv2d-23            [-1, 256, 7, 7]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 7, 7]             512\n",
      "             ReLU-25            [-1, 256, 7, 7]               0\n",
      "       Bottleneck-26            [-1, 256, 7, 7]               0\n",
      "           Conv2d-27             [-1, 64, 7, 7]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 7, 7]             128\n",
      "             ReLU-29             [-1, 64, 7, 7]               0\n",
      "           Conv2d-30             [-1, 64, 7, 7]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 7, 7]             128\n",
      "             ReLU-32             [-1, 64, 7, 7]               0\n",
      "           Conv2d-33            [-1, 256, 7, 7]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 7, 7]             512\n",
      "             ReLU-35            [-1, 256, 7, 7]               0\n",
      "       Bottleneck-36            [-1, 256, 7, 7]               0\n",
      "           Conv2d-37            [-1, 128, 7, 7]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 7, 7]             256\n",
      "             ReLU-39            [-1, 128, 7, 7]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                   [-1, 30]          61,470\n",
      "================================================================\n",
      "Total params: 23,563,294\n",
      "Trainable params: 23,563,294\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 5.18\n",
      "Params size (MB): 89.89\n",
      "Estimated Total Size (MB): 95.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet50, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, DEVICE):  \n",
    "    \"\"\"\n",
    "    Training function \n",
    "    Input : Model, Iterator = train data loader, Optimizer function,\n",
    "            Criterian, device = cuda or cpu \n",
    "    Output: Training Loss and Training Accuracy\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    for (X, y) in train_loader:\n",
    "        X = X.float().to(DEVICE)\n",
    "        y = y.type(torch.LongTensor).to(DEVICE)\n",
    "        \n",
    "        # preciction error\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    train_acc_list.append(epoch_acc/len(train_loader)) \n",
    "    train_loss_list.append(epoch_loss/len(train_loader)) \n",
    "        \n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader) , train_loss_list, train_acc_list\n",
    "\n",
    "def evaluate(model, test_loader, criterion, DEVICE):  \n",
    "    \"\"\"\n",
    "    Evaluation Function\n",
    "    Input : Model, iterator = test data loader, criterian of loss,\n",
    "            device = cuda or cpu\n",
    "    Output: Test loss, test accuracy\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (X, y) in test_loader:\n",
    "            X = X.float().to(DEVICE)\n",
    "            y = y.type(torch.LongTensor).to(DEVICE)\n",
    "\n",
    "            y_pred = model(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    \n",
    "    test_acc_list.append(epoch_acc/len(test_loader)) \n",
    "    test_loss_list.append(epoch_loss/len(test_loader))\n",
    "\n",
    "    return epoch_loss / len(test_loader), epoch_acc / len(test_loader) , test_loss_list, test_acc_list\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    \"\"\"\n",
    "    Function to calculate total time taken in an epoch\n",
    "    \"\"\"\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Counts the number of trainable parameters\n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of training/evaluating\n",
    "    \"\"\"\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_list, train_loss_list = [], []\n",
    "test_acc_list, test_loss_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Epoch: 01    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.455  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 02    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 03    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 04    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 05    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.455  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 06    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 07    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 08    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 09    | Epoch Time: 0m 12s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 10    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 11    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 12    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 13    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 14    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.455  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 15    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 16    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 17    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 18    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 19    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 20    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.455  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 21    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 22    | Epoch Time: 0m 9s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 23    | Epoch Time: 0m 11s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 24    | Epoch Time: 0m 13s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 25    | Epoch Time: 0m 13s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 26    | Epoch Time: 0m 11s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 27    | Epoch Time: 0m 11s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n",
      "-----------------------------------------------\n",
      "Epoch: 28    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 29    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.21%\n",
      "-----------------------------------------------\n",
      "Epoch: 30    | Epoch Time: 0m 10s\n",
      "-----------------------------------------------\n",
      "\tTrain Loss: 1.417 | Train Acc: 66.29%\n",
      "\tVal. Loss: 1.454  | Val. Acc: 65.22%\n"
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "#Variable to monitor best validation loss\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc, train_loss_list, train_acc_list = train(model, train_loader, criterion, optimizer, DEVICE)\n",
    "    valid_loss, valid_acc, test_loss_list, test_acc_list = evaluate(model, test_loader, criterion, DEVICE)\n",
    "    \n",
    "    #Saving model whenver the best validation loss is obtained\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs,  = epoch_time(start_time, end_time) #Monitoring Time\n",
    "    print('-----------------------------------------------')\n",
    "    print(f'Epoch: {epoch+1:02}    | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print('-----------------------------------------------')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\tVal. Loss: {valid_loss:.3f}  | Val. Acc: {valid_acc*100:.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2363f510d30>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "plt.plot(train_loss_list, label='Training loss')\n",
    "plt.plot(test_loss_list, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x236388dbf40>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "plt.plot(train_acc_list, label='Training Accuracy')\n",
    "plt.plot(test_acc_list, label='Validation Accuracy')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
